{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.233058Z",
     "iopub.status.busy": "2024-11-17T08:45:00.232630Z",
     "iopub.status.idle": "2024-11-17T08:45:00.237555Z",
     "shell.execute_reply": "2024-11-17T08:45:00.236537Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.233020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/arnav10goel/CSE556-NLP-Project.git\n",
    "# %cd CSE556-NLP-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.242639Z",
     "iopub.status.busy": "2024-11-17T08:45:00.242255Z",
     "iopub.status.idle": "2024-11-17T08:45:00.251317Z",
     "shell.execute_reply": "2024-11-17T08:45:00.250319Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.242589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset for the Particular Language\n",
    "\n",
    "- Here insert the language initial you want to load the train and test CSVs for\n",
    "\n",
    "- Language Codes:\n",
    "\n",
    "    1. Hindi: `hi`\n",
    "\n",
    "    2. Bengali: `bn`\n",
    "\n",
    "    3. Marathi: `mr`\n",
    "\n",
    "    4. Tamil: `ta`\n",
    "\n",
    "    5. Telugu: `te`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.253377Z",
     "iopub.status.busy": "2024-11-17T08:45:00.253058Z",
     "iopub.status.idle": "2024-11-17T08:45:00.321931Z",
     "shell.execute_reply": "2024-11-17T08:45:00.321115Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.253345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lang = 'Hindi'\n",
    "\n",
    "train_file = f\"/kaggle/working/CSE556-NLP-Project/Hate-Speech-Detection-Experiments/Dataset/{lang}_train.csv\"\n",
    "\n",
    "test_file = f\"/kaggle/working/CSE556-NLP-Project/Hate-Speech-Detection-Experiments/Dataset/{lang}_test.csv\"\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'Hindi'\n",
    "\n",
    "# Load train data from json\n",
    "train_path = f\"/kaggle/working/CSE556-NLP-Project/Hate-Speech-Detection-Experiments/Dataset/{lang}_train.json\"\n",
    "with open(train_path) as f:\n",
    "\n",
    "    train_data = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Load test data from json\n",
    "test_path = f\"/kaggle/working/CSE556-NLP-Project/Hate-Speech-Detection-Experiments/Dataset/{lang}_test.json\"\n",
    "with open(test_path) as f:\n",
    "\n",
    "    test_data = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Take the first 1000 samples for training \n",
    "\n",
    "train_data = train_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.323394Z",
     "iopub.status.busy": "2024-11-17T08:45:00.323063Z",
     "iopub.status.idle": "2024-11-17T08:45:00.337336Z",
     "shell.execute_reply": "2024-11-17T08:45:00.336461Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.323360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>Processed_Post</th>\n",
       "      <th>Labels Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sambitswaraj इसके मुह की साइज़ देखो\\n\\nस्लीपर...</td>\n",
       "      <td>1</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>इसके मुह की साइज़ देखो स्लीपर चप्पल जैसी</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>सबसे ज्यादा खुशी तब होती है जब आप किसी को 100 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>सबसे ज्यादा खुशी तब होती है जब आप किसी को या क...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@laluprasadrjd एक बात तो कंफर्म हो गई है तू बह...</td>\n",
       "      <td>1</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>एक बात तो कंफर्म हो गई है तू बहुत बेशर्म इंसान...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>रोहित सरदाना का शव कोविड पॉज़िटिव होने के बावज...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>रोहित सरदाना का शव कोविड पॉज़िटिव होने के बावज...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@abhishek_india1 @SHIFUJIJAIHIND @Rahul_IND1 @...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>राष्ट्रपतिजीबंगालसंभालो</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>RT @TejYadav14: खुद को कहता ये चौकीदार है।\\nले...</td>\n",
       "      <td>1</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>खुद को कहता ये चौकीदार है लेकिन नफरत फैलाना और...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>RT @MohammadSherAl6: प्लेन को बादल में छुपवा द...</td>\n",
       "      <td>1</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>प्लेन को बादल में छुपवा दियाये आदमी पीएम होकर ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>क्या क्या नहीं फेंकता है ये फेंकू कभी कालाधन ल...</td>\n",
       "      <td>1</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>क्या क्या नहीं फेंकता है ये फेंकू कभी कालाधन ल...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>2 /2llकहाँ है? सनद रहे कि यही आरजेडी पहले से ह...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>कहाँ है सनद रहे कि यही आरजेडी पहले से ही दिल्ल...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>राजद के नवादा ज़िला अध्यक्ष कमरुल बारी साहब ने...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>राजद के नवादा ज़िला अध्यक्ष कमरुल बारी साहब ने...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  task_1 task_2  \\\n",
       "0     @sambitswaraj इसके मुह की साइज़ देखो\\n\\nस्लीपर...       1   OFFN   \n",
       "1     सबसे ज्यादा खुशी तब होती है जब आप किसी को 100 ...       0   NONE   \n",
       "2     @laluprasadrjd एक बात तो कंफर्म हो गई है तू बह...       1   OFFN   \n",
       "3     रोहित सरदाना का शव कोविड पॉज़िटिव होने के बावज...       0   NONE   \n",
       "4     @abhishek_india1 @SHIFUJIJAIHIND @Rahul_IND1 @...       0   NONE   \n",
       "...                                                 ...     ...    ...   \n",
       "3995  RT @TejYadav14: खुद को कहता ये चौकीदार है।\\nले...       1   OFFN   \n",
       "3996  RT @MohammadSherAl6: प्लेन को बादल में छुपवा द...       1   OFFN   \n",
       "3997  क्या क्या नहीं फेंकता है ये फेंकू कभी कालाधन ल...       1   OFFN   \n",
       "3998  2 /2llकहाँ है? सनद रहे कि यही आरजेडी पहले से ह...       0   NONE   \n",
       "3999  राजद के नवादा ज़िला अध्यक्ष कमरुल बारी साहब ने...       0   NONE   \n",
       "\n",
       "                                         Processed_Post  Labels Set  \n",
       "0              इसके मुह की साइज़ देखो स्लीपर चप्पल जैसी           1  \n",
       "1     सबसे ज्यादा खुशी तब होती है जब आप किसी को या क...           0  \n",
       "2     एक बात तो कंफर्म हो गई है तू बहुत बेशर्म इंसान...           1  \n",
       "3     रोहित सरदाना का शव कोविड पॉज़िटिव होने के बावज...           0  \n",
       "4                               राष्ट्रपतिजीबंगालसंभालो           0  \n",
       "...                                                 ...         ...  \n",
       "3995  खुद को कहता ये चौकीदार है लेकिन नफरत फैलाना और...           1  \n",
       "3996  प्लेन को बादल में छुपवा दियाये आदमी पीएम होकर ...           1  \n",
       "3997  क्या क्या नहीं फेंकता है ये फेंकू कभी कालाधन ल...           1  \n",
       "3998  कहाँ है सनद रहे कि यही आरजेडी पहले से ही दिल्ल...           0  \n",
       "3999  राजद के नवादा ज़िला अध्यक्ष कमरुल बारी साहब ने...           0  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "\n",
    "- This class can be used for all Sentiment Analysis fine-tuning and zero shot tasks\n",
    "\n",
    "- For multiple languages, combine data into one dataframe as the dataset class takes DATAFRAME as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.339807Z",
     "iopub.status.busy": "2024-11-17T08:45:00.339376Z",
     "iopub.status.idle": "2024-11-17T08:45:00.348429Z",
     "shell.execute_reply": "2024-11-17T08:45:00.347721Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.339759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultilingualSentimentAnalysis_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataframe)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        label = self.dataframe.iloc[idx][\"Labels Set\"]\n",
    "\n",
    "        input_text = self.dataframe.iloc[idx][\"Processed_Post\"]\n",
    "\n",
    "        if pd.isna(input_text):\n",
    "\n",
    "            input_text = \"\"\n",
    "\n",
    "\n",
    "\n",
    "        # Tokenize\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "\n",
    "            input_text, None,\n",
    "\n",
    "            add_special_tokens=True,\n",
    "\n",
    "            max_length=self.max_length,\n",
    "\n",
    "            padding='max_length',\n",
    "\n",
    "            truncation=True,\n",
    "\n",
    "            return_tensors='pt'  # Corrected the argument here\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:00.349789Z",
     "iopub.status.busy": "2024-11-17T08:45:00.349492Z",
     "iopub.status.idle": "2024-11-17T08:45:03.205956Z",
     "shell.execute_reply": "2024-11-17T08:45:03.205108Z",
     "shell.execute_reply.started": "2024-11-17T08:45:00.349758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "# Get the model name\n",
    "\n",
    "model_name = \"ai4bharat/indic-bert\"\n",
    "\n",
    "\n",
    "\n",
    "# Initialise the tokeniser\n",
    "\n",
    "# Initialize IndicBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:03.207485Z",
     "iopub.status.busy": "2024-11-17T08:45:03.207167Z",
     "iopub.status.idle": "2024-11-17T08:45:03.213275Z",
     "shell.execute_reply": "2024-11-17T08:45:03.212327Z",
     "shell.execute_reply.started": "2024-11-17T08:45:03.207453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialise dataset instances\n",
    "\n",
    "train_dataset = MultilingualSentimentAnalysis_Dataset(train_df, tokenizer)\n",
    "\n",
    "dev_dataset = MultilingualSentimentAnalysis_Dataset(test_df, tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "# Initialise the dataloaders\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:03.215100Z",
     "iopub.status.busy": "2024-11-17T08:45:03.214533Z",
     "iopub.status.idle": "2024-11-17T08:45:03.223943Z",
     "shell.execute_reply": "2024-11-17T08:45:03.223110Z",
     "shell.execute_reply.started": "2024-11-17T08:45:03.215057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class MBertForSentimentAnalysis(nn.Module):\n",
    "\n",
    "    def __init__(self, freeze_bert=False):\n",
    "\n",
    "        super(MBertForSentimentAnalysis, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Load mBERT model and tokenizer\n",
    "\n",
    "        self.model_name = \"ai4bharat/indic-bert\"\n",
    "\n",
    "        # tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.mbert = AutoModel.from_pretrained(self.model_name)\n",
    "\n",
    "\n",
    "\n",
    "        # Add a batch normalization layer\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(self.mbert.config.hidden_size)\n",
    "\n",
    "        \n",
    "\n",
    "        # Add a linear layer for classification\n",
    "\n",
    "        self.classification = nn.Linear(self.mbert.config.hidden_size, 2)\n",
    "\n",
    "\n",
    "\n",
    "        # Option to freeze MBERT layers to prevent them from being updated during training\n",
    "\n",
    "        if freeze_bert:\n",
    "\n",
    "            for param in self.mbert.parameters():\n",
    "\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        # Get the output from BERT model\n",
    "\n",
    "        _, pooled_outputs = self.mbert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "\n",
    "\n",
    "\n",
    "        # Pass output through batch normalization layer\n",
    "\n",
    "        pooled_outputs = self.batch_norm(pooled_outputs)\n",
    "\n",
    "        \n",
    "\n",
    "        # Pass output through linear layer\n",
    "\n",
    "        out = self.classification(pooled_outputs)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pass freeze as true when doing zero shot to prevent BERT from getting fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:03.226300Z",
     "iopub.status.busy": "2024-11-17T08:45:03.226011Z",
     "iopub.status.idle": "2024-11-17T08:45:03.455402Z",
     "shell.execute_reply": "2024-11-17T08:45:03.454409Z",
     "shell.execute_reply.started": "2024-11-17T08:45:03.226269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "# Freeze BERT encoder to prevent fine-tuning\n",
    "\n",
    "model = MBertForSentimentAnalysis(freeze_bert=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    model.to(device)  # Move model to CUDA device if available\n",
    "\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "else:\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"CUDA is not available. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:45:03.457135Z",
     "iopub.status.busy": "2024-11-17T08:45:03.456710Z",
     "iopub.status.idle": "2024-11-17T08:49:27.478363Z",
     "shell.execute_reply": "2024-11-17T08:49:27.477380Z",
     "shell.execute_reply.started": "2024-11-17T08:45:03.457091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Train Loss: 0.7602, Validation Loss: 0.6972\n",
      "Epoch 2/4, Train Loss: 0.7063, Validation Loss: 0.6931\n",
      "Epoch 3/4, Train Loss: 0.6961, Validation Loss: 0.6881\n",
      "Epoch 4/4, Train Loss: 0.6928, Validation Loss: 0.6854\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "mse_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 4\n",
    "\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Training\n",
    "\n",
    "    model.train()  \n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "\n",
    "        # Forward pass\n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "        loss = mse_loss(outputs, inputs['labels'].long())\n",
    "\n",
    "\n",
    "\n",
    "        # Backward pass and optimize\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients during validation\n",
    "\n",
    "        for batch in dev_dataloader:\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "            loss = mse_loss(outputs, inputs['labels'].long())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "    avg_val_loss = val_loss / len(dev_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "    # Append the losses for plotting\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Fine-Tuned Model\n",
    "\n",
    "- Evaluate fine-tuned model on test dataset of each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:49:27.479992Z",
     "iopub.status.busy": "2024-11-17T08:49:27.479645Z",
     "iopub.status.idle": "2024-11-17T08:49:41.357360Z",
     "shell.execute_reply": "2024-11-17T08:49:41.356446Z",
     "shell.execute_reply.started": "2024-11-17T08:49:27.479958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR Hindi\n",
      "\n",
      "Accuracy: 0.5640\n",
      "Weighted F1-score: 0.5637\n",
      "Macro F1-score: 0.5637\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.58       500\n",
      "           1       0.57      0.54      0.55       500\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.56      0.56      0.56      1000\n",
      "weighted avg       0.56      0.56      0.56      1000\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[296 204]\n",
      " [232 268]]\n",
      "\n",
      "----------*******************---------------\n"
     ]
    }
   ],
   "source": [
    "# Load datasets for each language\n",
    "\n",
    "languages = [\"Hindi\"]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for lang in languages:\n",
    "\n",
    "        test_file = f\"/kaggle/working/CSE556-NLP-Project/Hate-Speech-Detection-Experiments/Dataset/{lang}_test.csv\"\n",
    "\n",
    "        test_df = pd.read_csv(test_file)\n",
    "\n",
    "        test_dataloader = DataLoader(MultilingualSentimentAnalysis_Dataset(test_df, tokenizer), batch_size=16, shuffle=True)\n",
    "\n",
    "        \n",
    "\n",
    "        # Make list for predicted labels and ground truth labels\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        labels = []\n",
    "\n",
    "\n",
    "\n",
    "        # Perform inference\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "            predicted_labels.extend(torch.argmax(outputs, dim=1).tolist())\n",
    "\n",
    "            labels.extend(inputs['labels'].long().tolist())\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Print results for a particular language\n",
    "\n",
    "        print(f\"RESULTS FOR {lang}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Calculate accuracy\n",
    "\n",
    "        accuracy = accuracy_score(labels, predicted_labels) \n",
    "\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate F1-score\n",
    "\n",
    "        weighted_f1_score = f1_score(labels, predicted_labels, average='weighted')\n",
    "\n",
    "        macro_f1_score = f1_score(labels, predicted_labels, average='macro')\n",
    "\n",
    "        print(f'Weighted F1-score: {weighted_f1_score:.4f}')\n",
    "\n",
    "        print(f'Macro F1-score: {macro_f1_score:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "\n",
    "        # Print classification report\n",
    "\n",
    "        print(\"Classification Report\")\n",
    "\n",
    "        print(classification_report(labels, predicted_labels))\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Print confusion matrix\n",
    "\n",
    "        print(\"Confusion Matrix\")\n",
    "\n",
    "        print(confusion_matrix(labels, predicted_labels))\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\"----------*******************---------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T08:49:41.358968Z",
     "iopub.status.busy": "2024-11-17T08:49:41.358601Z",
     "iopub.status.idle": "2024-11-17T08:49:41.605049Z",
     "shell.execute_reply": "2024-11-17T08:49:41.604117Z",
     "shell.execute_reply.started": "2024-11-17T08:49:41.358930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save Model and Tokenizer\n",
    "\n",
    "model_save_path = \"IndicBERT_HS_Hi_ZeroShot.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
