{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9926113,"sourceType":"datasetVersion","datasetId":6101008}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom transformers import BertTokenizerFast, BertModel\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport string\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:33:38.772894Z","iopub.execute_input":"2024-11-17T13:33:38.773581Z","iopub.status.idle":"2024-11-17T13:33:45.046737Z","shell.execute_reply.started":"2024-11-17T13:33:38.773539Z","shell.execute_reply":"2024-11-17T13:33:45.045973Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"lang = 'hindi'\n\n# Load train data from json\nwith open(f'/kaggle/input/llm-project/{lang}_train.json') as f:\n    train_data = json.load(f)\n\n# Load test data from json\nwith open(f'/kaggle/input/llm-project/{lang}_test.json') as f:\n    test_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:33:50.495093Z","iopub.execute_input":"2024-11-17T13:33:50.495618Z","iopub.status.idle":"2024-11-17T13:33:50.548664Z","shell.execute_reply.started":"2024-11-17T13:33:50.495583Z","shell.execute_reply":"2024-11-17T13:33:50.547905Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load tokeniser for MBERT\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:33:51.623708Z","iopub.execute_input":"2024-11-17T13:33:51.624089Z","iopub.status.idle":"2024-11-17T13:33:58.157790Z","shell.execute_reply.started":"2024-11-17T13:33:51.624055Z","shell.execute_reply":"2024-11-17T13:33:58.156843Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e9df0e38b874c3885401ca2aebcdf58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e82f1583f6470497c7c9d5c842e752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a031304635be49ceb5335128de1010f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b990070427284756b8fd165b75fcc29a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class NER_Dataset(Dataset):\n    def __init__(self, data, tokenizer, max_len=128):\n        self.data = data  # List of sentences and labels\n        self.tokenizer = tokenizer  # mBERT tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data[idx][\"tokens\"]\n        word_labels = self.data[idx][\"ner_tags\"]\n\n        # Tokenize the text and align the labels\n        encoding = self.tokenizer(text,\n                                  is_split_into_words=True,\n                                  return_offsets_mapping=True,\n                                  padding='max_length',\n                                  truncation=True,\n                                  max_length=self.max_len)\n\n        labels = [self.align_labels(encoding['offset_mapping'], word_labels)]\n\n        # Remove the offset mapping to prevent issues during model training\n        del encoding['offset_mapping']\n\n        item = {key: torch.tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.tensor(labels[0], dtype=torch.long)\n\n        return item\n    \n    # Create a function to align labels\n    def align_labels(self, offset_mapping, labels):\n        aligned_labels = []\n        current_label_index = 0\n\n        for offset in offset_mapping:\n            # If the offset mapping is (0, 0), it's a special token ([CLS], [SEP], [PAD])\n            if offset == (0, 0):\n                aligned_labels.append(-100)  # -100 is used to ignore these tokens in the loss computation\n            else:\n                # Check if the token is the start of a new word\n                if offset[0] == 0:\n                    aligned_labels.append(labels[current_label_index])\n                    current_label_index += 1\n                else:\n                    # If the token is not the first subtoken, you can decide how to label it. \n                    # For simplicity, let's use the same label as the first subtoken\n                    aligned_labels.append(labels[current_label_index - 1])\n\n        return aligned_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:33:58.214767Z","iopub.execute_input":"2024-11-17T13:33:58.215070Z","iopub.status.idle":"2024-11-17T13:33:58.225984Z","shell.execute_reply.started":"2024-11-17T13:33:58.215038Z","shell.execute_reply":"2024-11-17T13:33:58.224981Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create train dataset and test dataset\ntrain_dataset = NER_Dataset(train_data, tokenizer)\ntest_dataset = NER_Dataset(test_data, tokenizer)\n\n# Create train dataloader and test dataloader\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:33:58.255683Z","iopub.execute_input":"2024-11-17T13:33:58.256055Z","iopub.status.idle":"2024-11-17T13:33:58.261707Z","shell.execute_reply.started":"2024-11-17T13:33:58.256013Z","shell.execute_reply":"2024-11-17T13:33:58.260830Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\n# Model for NER\nclass MBERT_NER(nn.Module):\n    def __init__(self, num_labels, gru_hidden_size, num_gru_layers, freeze_bert=False):\n        super(MBERT_NER, self).__init__()\n        self.bert = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n        self.gru = nn.GRU(input_size=self.bert.config.hidden_size,\n                          hidden_size=gru_hidden_size,\n                          num_layers=num_gru_layers,\n                          batch_first=True)\n        self.classifier = nn.Linear(gru_hidden_size, num_labels)\n        self.dropout = nn.Dropout(0.1)\n        self.batch_norm = nn.BatchNorm1d(gru_hidden_size)\n\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state\n        gru_output, _ = self.gru(sequence_output)\n        gru_output = self.batch_norm(gru_output)\n        gru_output = self.dropout(gru_output)\n        logits = self.classifier(gru_output)\n        return logits\n\n# Create the NER model\nNUM_LABELS = 7 # Number of NER tags\nGRU_HIDDEN_SIZE = 128 # Hidden size of the GRU\nNUM_GRU_LAYERS = 1 # Number of layers in the GRU\nFREEZE_BERT = False # Whether to freeze the BERT model\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = MBERT_NER(num_labels=NUM_LABELS,\n                    gru_hidden_size=GRU_HIDDEN_SIZE,\n                    num_gru_layers=NUM_GRU_LAYERS,\n                    freeze_bert=FREEZE_BERT)\n\nmodel.to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:34:38.676975Z","iopub.execute_input":"2024-11-17T13:34:38.677642Z","iopub.status.idle":"2024-11-17T13:34:48.088579Z","shell.execute_reply.started":"2024-11-17T13:34:38.677604Z","shell.execute_reply":"2024-11-17T13:34:48.087674Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af5ba5523de4a6bafb4fca0e4908810"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2297c363c1243db8666f2472077963f"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"MBERT_NER(\n  (bert): AlbertModel(\n    (embeddings): AlbertEmbeddings(\n      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n      (position_embeddings): Embedding(512, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0, inplace=False)\n    )\n    (encoder): AlbertTransformer(\n      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n      (albert_layer_groups): ModuleList(\n        (0): AlbertLayerGroup(\n          (albert_layers): ModuleList(\n            (0): AlbertLayer(\n              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (attention): AlbertSdpaAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (attention_dropout): Dropout(p=0, inplace=False)\n                (output_dropout): Dropout(p=0, inplace=False)\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              )\n              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n              (activation): GELUActivation()\n              (dropout): Dropout(p=0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (pooler): Linear(in_features=768, out_features=768, bias=True)\n    (pooler_activation): Tanh()\n  )\n  (gru): GRU(768, 128, batch_first=True)\n  (classifier): Linear(in_features=128, out_features=7, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\n\n# Optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss(ignore_index=-100)\n\n# Training loop\nEPOCHS = 6\n\ntrain_losses = []\ntrain_f1_scores = []\ntrain_acc_scores = []\nval_losses = []\nval_f1_scores = []\nval_acc_scores = []\n\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    train_predictions, train_labels = [], []\n\n    for batch in train_dataloader:\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        logits = logits.view(-1, NUM_LABELS)\n        labels = labels.view(-1)\n\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n        # Get predictions and filter out ignored indices for metric calculations\n        predictions = torch.argmax(logits, dim=-1)\n        active_indices = labels != -100\n        train_predictions.extend(predictions[active_indices].cpu().numpy())\n        train_labels.extend(labels[active_indices].cpu().numpy())\n\n    train_loss /= len(train_dataloader)\n    train_losses.append(train_loss)\n\n    train_f1 = f1_score(train_labels, train_predictions, average='macro')\n    train_f1_scores.append(train_f1)\n\n    train_acc = accuracy_score(train_labels, train_predictions)\n    train_acc_scores.append(train_acc)\n\n    # Validation loop\n    model.eval()\n    val_loss = 0\n    val_predictions, val_labels = [], []\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(DEVICE)\n            attention_mask = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n\n            logits = model(input_ids, attention_mask)\n            logits = logits.view(-1, NUM_LABELS)\n            labels = labels.view(-1)\n\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n\n            # Filter predictions and labels\n            predictions = torch.argmax(logits, dim=-1)\n            active_indices = labels != -100\n            val_predictions.extend(predictions[active_indices].cpu().numpy())\n            val_labels.extend(labels[active_indices].cpu().numpy())\n\n    val_loss /= len(test_dataloader)\n    val_losses.append(val_loss)\n\n    val_f1 = f1_score(val_labels, val_predictions, average='macro')\n    val_f1_scores.append(val_f1)\n\n    val_acc = accuracy_score(val_labels, val_predictions)\n    val_acc_scores.append(val_acc)\n\n    print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}, Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:34:48.145790Z","iopub.execute_input":"2024-11-17T13:34:48.146106Z","iopub.status.idle":"2024-11-17T13:43:02.400999Z","shell.execute_reply.started":"2024-11-17T13:34:48.146074Z","shell.execute_reply":"2024-11-17T13:43:02.399990Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/6, Train Loss: 1.5139, Train F1: 0.2573, Train Acc: 0.4580, Val Loss: 1.2055, Val F1: 0.4176, Val Acc: 0.5968\nEpoch 2/6, Train Loss: 1.0768, Train F1: 0.4810, Train Acc: 0.6279, Val Loss: 0.9736, Val F1: 0.5382, Val Acc: 0.6756\nEpoch 3/6, Train Loss: 0.8351, Train F1: 0.6056, Train Acc: 0.7160, Val Loss: 0.9220, Val F1: 0.5601, Val Acc: 0.6869\nEpoch 4/6, Train Loss: 0.6453, Train F1: 0.7072, Train Acc: 0.7864, Val Loss: 0.8051, Val F1: 0.6636, Val Acc: 0.7434\nEpoch 5/6, Train Loss: 0.5008, Train F1: 0.7833, Train Acc: 0.8406, Val Loss: 0.8347, Val F1: 0.6460, Val Acc: 0.7382\nEpoch 6/6, Train Loss: 0.4159, Train F1: 0.8243, Train Acc: 0.8692, Val Loss: 0.7636, Val F1: 0.6966, Val Acc: 0.7667\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# Load the test data from json for all 5 languages\nlanguages = ['hindi', 'bengali', 'marathi', 'tamil', 'telugu']\n\n# Iterate over all languages and evaluate the model\nfor lang in languages:\n    with open(f'/kaggle/input/llm-project/{lang}_test.json') as f:\n        test_data = json.load(f)\n\n    test_dataset = NER_Dataset(test_data, tokenizer)\n    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n    model.eval()\n    test_predictions, test_labels = [], []\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(DEVICE)\n            attention_mask = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n\n            logits = model(input_ids, attention_mask)\n            logits = logits.view(-1, NUM_LABELS)\n            labels = labels.view(-1)\n\n            # Filter predictions and labels\n            predictions = torch.argmax(logits, dim=-1)\n            active_indices = labels != -100\n            test_predictions.extend(predictions[active_indices].cpu().numpy())\n            test_labels.extend(labels[active_indices].cpu().numpy())\n\n    weighted_f1 = f1_score(test_labels, test_predictions, average='weighted')\n    macro_f1 = f1_score(test_labels, test_predictions, average='macro')\n    accuracy = accuracy_score(test_labels, test_predictions)\n\n    if lang == 'hindi':\n        LANG = \"Hindi\"\n    elif lang == 'bengali':\n        LANG = \"Bengali\"\n    elif lang == 'marathi':\n        LANG = \"Marathi\"\n    elif lang == 'tamil':\n        LANG = \"Tamil\"\n    elif lang == 'telugu':\n        LANG = \"Telugu\"\n\n    print(f\"Language: {LANG}\")\n    print()\n    print(f\"Weighted F1: {weighted_f1:.4f}\")\n    print(f\"Macro F1: {macro_f1:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print()\n    print(\"CLASSIFICATION REPORT: \")\n    print(classification_report(test_labels, test_predictions))\n    print()\n    print(\"CONFUSION MATRIX: \")\n    print(confusion_matrix(test_labels, test_predictions))\n    print(\"--------------------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:43:27.898534Z","iopub.execute_input":"2024-11-17T13:43:27.899418Z","iopub.status.idle":"2024-11-17T13:44:01.785234Z","shell.execute_reply.started":"2024-11-17T13:43:27.899380Z","shell.execute_reply":"2024-11-17T13:44:01.784128Z"}},"outputs":[{"name":"stdout","text":"Language: Hindi\n\nWeighted F1: 0.7670\nMacro F1: 0.6966\nAccuracy: 0.7667\n\nCLASSIFICATION REPORT: \n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89      5277\n           1       0.73      0.65      0.69      1481\n           2       0.72      0.72      0.72      1874\n           3       0.71      0.63      0.67       986\n           4       0.85      0.74      0.79      2602\n           5       0.59      0.60      0.60      1195\n           6       0.46      0.59      0.52       867\n\n    accuracy                           0.77     14282\n   macro avg       0.70      0.69      0.70     14282\nweighted avg       0.77      0.77      0.77     14282\n\n\nCONFUSION MATRIX: \n[[4852   62   91    9   54  142   67]\n [ 107  962  176   80   22   99   35]\n [ 124  107 1343   13  109   24  154]\n [  81   80   14  626   66   97   22]\n [ 171   18  161   76 1931   45  200]\n [ 163   72   24   67   33  721  115]\n [ 105   17   58   11   64   97  515]]\n--------------------------------------------------\nLanguage: Bengali\n\nWeighted F1: 0.2920\nMacro F1: 0.2862\nAccuracy: 0.3222\n\nCLASSIFICATION REPORT: \n              precision    recall  f1-score   support\n\n           0       0.31      0.94      0.46      1835\n           1       0.31      0.16      0.21      1343\n           2       0.37      0.14      0.20      2490\n           3       0.31      0.23      0.26      1239\n           4       0.45      0.32      0.37      3068\n           5       0.27      0.30      0.29      1510\n           6       0.24      0.18      0.20      2080\n\n    accuracy                           0.32     13565\n   macro avg       0.32      0.32      0.29     13565\nweighted avg       0.34      0.32      0.29     13565\n\n\nCONFUSION MATRIX: \n[[1724   15   13    2    4   64   13]\n [ 484  221   31  251   51  265   40]\n [ 918   67  342   51  518  166  428]\n [ 288  152   40  286  130  281   62]\n [ 872   58  266   82  976  244  570]\n [ 494  156   45  231   51  454   79]\n [ 817   50  184   19  443  199  368]]\n--------------------------------------------------\nLanguage: Marathi\n\nWeighted F1: 0.5363\nMacro F1: 0.3310\nAccuracy: 0.5483\n\nCLASSIFICATION REPORT: \n              precision    recall  f1-score   support\n\n           0       0.75      0.79      0.77     10408\n           1       0.39      0.25      0.30      1342\n           2       0.34      0.34      0.34      1992\n           3       0.21      0.12      0.15      1172\n           4       0.34      0.45      0.38      2535\n           5       0.30      0.20      0.24      1829\n           6       0.13      0.14      0.13       820\n\n    accuracy                           0.55     20098\n   macro avg       0.35      0.33      0.33     20098\nweighted avg       0.53      0.55      0.54     20098\n\n\nCONFUSION MATRIX: \n[[8264  212  271  254  796  419  192]\n [ 289  336  276   80  201  122   38]\n [ 467   33  670   24  493  101  204]\n [ 330  118  141  144  321   84   34]\n [ 657   37  436   27 1131   37  210]\n [ 789  119   92  150  220  363   96]\n [ 290    9   82   13  213  102  111]]\n--------------------------------------------------\nLanguage: Tamil\n\nWeighted F1: 0.4538\nMacro F1: 0.2261\nAccuracy: 0.5088\n\nCLASSIFICATION REPORT: \n              precision    recall  f1-score   support\n\n           0       0.63      0.85      0.72     11461\n           1       0.21      0.04      0.07      1643\n           2       0.17      0.04      0.06      2295\n           3       0.23      0.11      0.15      1512\n           4       0.34      0.27      0.30      2532\n           5       0.19      0.25      0.22      1881\n           6       0.06      0.07      0.07       677\n\n    accuracy                           0.51     22001\n   macro avg       0.26      0.23      0.23     22001\nweighted avg       0.44      0.51      0.45     22001\n\n\nCONFUSION MATRIX: \n[[9687   68   71  251  377  930   77]\n [ 883   73   30  102  139  381   35]\n [1327   11   81   31  403  232  210]\n [ 717   91   53  159  189  239   64]\n [1249   31  140   45  675  163  229]\n [1051   70   63   82   79  473   63]\n [ 364    7   34   11  141   73   47]]\n--------------------------------------------------\nLanguage: Telugu\n\nWeighted F1: 0.5644\nMacro F1: 0.2037\nAccuracy: 0.6332\n\nCLASSIFICATION REPORT: \n              precision    recall  f1-score   support\n\n           0       0.71      0.92      0.80     17291\n           1       0.16      0.04      0.06      1810\n           2       0.11      0.03      0.05      1353\n           3       0.14      0.04      0.06      1375\n           4       0.32      0.11      0.16      2269\n           5       0.27      0.22      0.25      2072\n           6       0.04      0.04      0.04       455\n\n    accuracy                           0.63     26625\n   macro avg       0.25      0.20      0.20     26625\nweighted avg       0.53      0.63      0.56     26625\n\n\nCONFUSION MATRIX: \n[[15963   124    67   138   230   723    46]\n [ 1400    69    32    65    38   185    21]\n [ 1022     1    47     7   114    77    85]\n [ 1031    91    33    50    40    92    38]\n [ 1493    72   178    20   251    99   156]\n [ 1314    72    61    62    52   462    49]\n [  308     5     7     5    61    51    18]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), f'NER_FineTune_{lang}.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:44:10.212450Z","iopub.execute_input":"2024-11-17T13:44:10.213224Z","iopub.status.idle":"2024-11-17T13:44:10.464436Z","shell.execute_reply.started":"2024-11-17T13:44:10.213184Z","shell.execute_reply":"2024-11-17T13:44:10.463615Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}